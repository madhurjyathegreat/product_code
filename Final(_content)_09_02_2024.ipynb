{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1x1CRLY-VUX"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "WnBMUZ0v-ZOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import re\n",
        "data = pd.read_excel(\"/content/flipkart_data.xlsx\")\n",
        "\n",
        "\n",
        "def madhur(source):\n",
        "    filtered_data=data[(data['componentClassName']== source) & (data['appName']==source)]\n",
        "    filtered_data.Text.to_list()\n",
        "    concatenated_string=\" \".join(str(i) for i in filtered_data['Text'])\n",
        "    #from langchain.chat_models import AzureChatOpenAI\n",
        "    #from langchain.chat_models import ChatOpenAI\n",
        "    # from langchain.chains import GraphCypherQAChain\n",
        "    # from langchain.graphs import Neo4jGraph\n",
        "    # from langchain.schema import HumanMessage\n",
        "    # llm = AzureChatOpenAI(\n",
        "    #         openai_api_base='https://xgptopenai.openai.azure.com/',\n",
        "    #         openai_api_version=\"2023-05-15\",\n",
        "    #         deployment_name='xgptopenai',\n",
        "    #         openai_api_key='174d1e2747d54e5291fa10b7f6cb8286',\n",
        "    #         openai_api_type=\"azure\",\n",
        "    #         temperature=0\n",
        "    #     )\n",
        "    cleaned_df = filtered_data['Text'].drop_duplicates(keep='last')\n",
        "    clean_data=\" \".join(str(i) for i in cleaned_df)\n",
        "    \"\"\"Products for chekout\"\"\"\n",
        "    import re\n",
        "    match = re.search(r'\\ Place order\\b', clean_data)\n",
        "    pattern = re.compile(r'\\ Place order\\b')\n",
        "\n",
        "    # Find all matches in the passage\n",
        "    matches = pattern.finditer(clean_data)\n",
        "\n",
        "    # Get the positions of all matches\n",
        "    positions = [match.span() for match in matches]\n",
        "\n",
        "    place_order_context=clean_data[:positions[0][1]]\n",
        "    \"Adding qunatity pattern to pace order clean data context\"\n",
        "    \"\"\"Products for chekout and quatity keyword\"\"\"\n",
        "    match = re.search(r'\\ Quantity\\b', place_order_context)\n",
        "    pattern = re.compile(r'\\ Quantity\\b')\n",
        "\n",
        "    # Find all matches in the passage\n",
        "    matches = pattern.finditer(place_order_context)\n",
        "\n",
        "    # Get the positions of all matches\n",
        "    positions_quantity = [match.span() for match in matches]\n",
        "\n",
        "    fl_qunatiy=[]\n",
        "    start_pos=0\n",
        "    for i in positions_quantity:\n",
        "        temp_list=[]\n",
        "        end_pos=list(i)[1]\n",
        "        temp_list.append(start_pos)\n",
        "        temp_list.append(end_pos)\n",
        "        fl_qunatiy.append(temp_list)\n",
        "        start_pos=end_pos\n",
        "\n",
        "    products_bought=[]\n",
        "    for i in positions_quantity:\n",
        "        products_bought.append(place_order_context[:i[1]][::-1][:400][::-1])\n",
        "\n",
        "        #%%time\n",
        "    \"\"\"Rephrasing the products description\"\"\"\n",
        "    rephrased_context_products=[]\n",
        "    for i in products_bought:\n",
        "        r = model.generate_content(\"Rephrase the following\"+str(i))\n",
        "        rephrased_context_products.append(r.text)\n",
        "\n",
        "    def product_details_add_to_cart(string_injection_index):\n",
        "        \"\"\"Extract information of product based on the index of Add to cart indexes\"\"\"\n",
        "\n",
        "        #Prompt Enginerring to Answer Questions\n",
        "        \"\"\"Product Sub-Category\"\"\"\n",
        "        message_subcategory = model.generate_content(\"What is the sub-category of the product.Just extract the sub-category from the context.\"+string_injection_index)\n",
        "        output_subcategory= message_subcategory\n",
        "\n",
        "\n",
        "        #Prompt Enginerring to Answer Questions\n",
        "        \"\"\"Product Category\"\"\"\n",
        "        message_category = model.generate_content(\"What is the product category.Just name the category?\"+str(output_subcategory.text))\n",
        "        output_category= message_category\n",
        "\n",
        "\n",
        "        #Prompt Enginerring to Answer Questions\n",
        "        \"\"\"Product Colour\"\"\"\n",
        "        message_colour= model.generate_content (\"What is the product colour.Just tell the name of the colour.No need to write complete statement?\"+string_injection_index)\n",
        "        output_colour= message_colour\n",
        "\n",
        "\n",
        "\n",
        "        #Prompt Enginerring to Answer Questions\n",
        "        \"\"\"Product Price\"\"\"\n",
        "        message_price= model.generate_content (\"What is the price of the product added to cart.Extract only the numbers.\"+string_injection_index)\n",
        "        output_price= message_price\n",
        "        message_price_1 = model.generate_content (\"Extract only the numbers.\"+str(output_price.text))\n",
        "        output_price= message_price_1\n",
        "\n",
        "\n",
        "\n",
        "        #Prompt Enginerring to Answer Questions\n",
        "        \"\"\"Product Seller\"\"\"\n",
        "        message_seller= model.generate_content (\"Where is the  product that is added to the cart coming from.\"+string_injection_index)\n",
        "        output_seller= message_seller\n",
        "        message_seller_1= model.generate_content (\"Extract the product rating.\"+str(output_seller.text))\n",
        "        output_seller_1= message_seller_1\n",
        "\n",
        "\n",
        "        #Prompt Enginerring to Answer Questions\n",
        "        \"\"\"Product Specifications\"\"\"\n",
        "        message_specifications = model.generate_content (\"What are the product technical specifications for the product that is added to cart?\"+string_injection_index)\n",
        "        output_specifications= message_specifications\n",
        "        #Prompt Enginerring to Answer Questions\n",
        "        \"\"\"Product Specifications\"\"\"\n",
        "        message_specifications= model.generate_content (\"Remove the price,seller and the colour information and extract the remaining information fo the product.\"+str(output_specifications.text))\n",
        "        output_specifications_1= message_specifications\n",
        "        structured_message= model.generate_content (\n",
        "            \"What is the rating of the product according to the context?Extract only the rating no.\"+str(string_injection_index))\n",
        "        output_rating= structured_message\n",
        "        structured_message= model.generate_content (\n",
        "            \"Extract only the rating no. from the context\"+str(output_rating.text))\n",
        "        output_rating= structured_message\n",
        "\n",
        "        return output_category,output_subcategory,output_colour,output_price,output_seller_1,output_specifications_1,output_rating\n",
        "\n",
        "\n",
        "    #%%time\n",
        "    final_output=[]\n",
        "    for all_selected_products in rephrased_context_products:\n",
        "        output_category,output_subcategory,output_colour,output_price,output_seller_1,output_specifications_1,output_rating=product_details_add_to_cart(all_selected_products)\n",
        "        final_output.extend([output_category,output_subcategory,output_colour,output_price,output_seller_1,output_specifications_1,output_rating])\n",
        "\n",
        "    final_output_messages=[]\n",
        "    start_index=0\n",
        "    for i in range(int(len(final_output)/7)):\n",
        "        final_index=start_index+7\n",
        "        final_output_messages.append((final_output)[start_index:final_index])\n",
        "        start_index=final_index\n",
        "\n",
        "    import re\n",
        "    import pandas as pd\n",
        "\n",
        "    # Sample statement\n",
        "    additional_information_revised = []\n",
        "    for i in range(len(final_output_messages)):\n",
        "        statement = final_output_messages[i][5].text\n",
        "\n",
        "        # Regular expression pattern\n",
        "        pattern = r\"Product\\s\\d+\\s*:\"\n",
        "        matches = re.finditer(pattern, statement)\n",
        "        matches_no = re.findall(pattern, statement)\n",
        "\n",
        "        # Get the index position of the last match\n",
        "        last_match_index = None\n",
        "        for match in matches:\n",
        "            last_match_index = match.end()\n",
        "\n",
        "        # Print the index position of the last match\n",
        "        #print(\"Index position of the last match:\", last_match_index)\n",
        "        if len(matches_no) > 1:\n",
        "            additional_information_revised.append(final_output_messages[i][5].text[last_match_index:])\n",
        "        else:\n",
        "            additional_information_revised.append(final_output_messages[i][5].text)\n",
        "\n",
        "    category_final = []\n",
        "    sub_category_final = []\n",
        "    colour_final = []\n",
        "    price_final = []\n",
        "    output_seller_final = []\n",
        "    additional_info = []\n",
        "    output_rating = []\n",
        "\n",
        "    for i in range(len(final_output_messages)):\n",
        "        category_final.append(final_output_messages[i][0].text)\n",
        "        sub_category_final.append(final_output_messages[i][1].text)\n",
        "        colour_final.append(final_output_messages[i][2].text)\n",
        "        price_final.append(final_output_messages[i][3].text)\n",
        "        output_seller_final.append(final_output_messages[i][4].text)\n",
        "        additional_info.append(final_output_messages[i][5].text)\n",
        "        output_rating.append(final_output_messages[i][6].text)\n",
        "\n",
        "    df_output = pd.DataFrame()\n",
        "    df_output['category_final'] = category_final\n",
        "    df_output['sub_category_final'] = sub_category_final\n",
        "    df_output['colour_final'] = colour_final\n",
        "    df_output['price_final'] = price_final\n",
        "    df_output['output_seller_final'] = output_seller_final\n",
        "    df_output['additional_info'] = additional_info\n",
        "    df_output['output_rating'] = output_rating\n",
        "\n",
        "    # maggi chicken cubes,Bakson's Homoeopathy AC,6 bars of Nestle Munch Chocolate Crunchy Wa\n",
        "    rows_to_drop = []\n",
        "    for i in range(len(df_output)):\n",
        "        if 'Unfortunately' in df_output['additional_info'][i]:\n",
        "            rows_to_drop.append(i)\n",
        "        if len(df_output['price_final'][i].split(\",\")) > 1:\n",
        "            rows_to_drop.append(i)\n",
        "\n",
        "    # Drop the rows after iterating\n",
        "    df_output = df_output.drop(rows_to_drop)\n",
        "\n",
        "    # Reset the index to avoid gaps after dropping rows\n",
        "    df_output = df_output.reset_index(drop=True)\n",
        "\n",
        "    return df_output"
      ],
      "metadata": {
        "id": "nxyRfhvX-tH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}